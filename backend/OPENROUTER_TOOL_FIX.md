# OpenRouter Tool Usage Fix

## üéØ Issue Summary

**Problem**: Agents configured with MCP tools fail to use those tools when using OpenRouter as the LLM provider.

**Error**:
```
Error code: 404 - {
  'error': {
    'message': 'No endpoints found that support tool use. 
    To learn more about provider routing, visit: 
    https://openrouter.ai/docs/provider-routing',
    'code': 404
  }
}
```

## üîç Root Cause Analysis

### The Problem Chain

1. ‚úÖ **MCP tools ARE being loaded correctly**
   - Log confirms: `"Loaded 7 tools from MCP server Puppeteer"`
   - Log confirms: `"Creating ReAct agent with 7 tools"`
   - Tools are properly sanitized and bound to the LLM

2. ‚úÖ **Agent IS being created with tools**
   - `llm.bind_tools(tools)` is called successfully
   - `create_react_agent(llm_with_tools, tools=tools)` executes

3. ‚ùå **OpenRouter CANNOT route to tool-capable providers**
   - OpenRouter returns 404 "No endpoints found that support tool use"
   - The selected model or routing configuration doesn't support tools

### Why This Happened

When we previously fixed the `TypeError: AsyncCompletions.create() got an unexpected keyword argument 'provider'`, we **removed** the provider routing configuration entirely:

```python
# BEFORE (caused TypeError):
return ChatOpenAI(
    model=model,
    temperature=temperature,
    api_key=api_key,
    base_url="https://openrouter.ai/api/v1",
    model_kwargs={
        "provider": {
            "order": ["OpenAI", "Anthropic", ...],
            "allow_fallbacks": True
        }
    }
)
```

The problem with `model_kwargs` is that LangChain passes these as **Python keyword arguments** to the OpenAI SDK's `create()` method. Since the OpenAI SDK doesn't recognize a `provider` parameter, it raised a `TypeError`.

However, by removing this configuration entirely, we lost the ability to tell OpenRouter which providers to prefer for tool-capable requests.

## ‚úÖ Solution

### Use `extra_body` Instead of `model_kwargs`

The OpenAI Python SDK supports an `extra_body` parameter that adds fields directly to the JSON request body without passing them as Python kwargs. This is the correct way to send OpenRouter-specific fields.

```python
# AFTER (correct approach):
return ChatOpenAI(
    model=model,
    temperature=temperature,
    api_key=api_key,
    base_url="https://openrouter.ai/api/v1",
    default_headers={
        "HTTP-Referer": "https://execution-plane.local",
        "X-Title": "Execution Plane Agent"
    },
    extra_body={
        "provider": {
            "order": [
                "OpenAI",      # Supports tools
                "Anthropic",   # Supports tools
                "Google",      # Supports tools
                "Cohere",      # Supports tools
                "Fireworks"    # Supports tools
            ],
            "allow_fallbacks": True
        }
    }
)
```

### How It Works

1. **`extra_body`** adds the `provider` field to the JSON request body
2. OpenRouter receives the routing preferences in the request
3. OpenRouter routes the request to a provider that supports tool use
4. The agent can now successfully use MCP tools

## üìä Comparison

| Approach | Python Kwargs | JSON Body | Tool Support |
|----------|--------------|-----------|--------------|
| **`model_kwargs`** | ‚úÖ Yes | ‚ùå No | ‚ùå TypeError |
| **No routing** | ‚ùå No | ‚ùå No | ‚ùå 404 No endpoints |
| **`extra_body`** | ‚ùå No | ‚úÖ Yes | ‚úÖ Works |

## üß™ Testing

### Test Case 1: OpenRouter Agent with MCP Tools

**Before Fix**:
```
ERROR: Error code: 404 - No endpoints found that support tool use
```

**After Fix**:
```
‚úÖ OpenRouter routes to tool-capable provider (e.g., OpenAI, Anthropic)
‚úÖ Agent successfully uses MCP tools
‚úÖ No TypeError or 404 errors
```

### Test Case 2: Other Providers (Groq, OpenAI, Anthropic)

**Status**: ‚úÖ Unchanged - continues to work correctly

## üéØ Files Modified

1. **`services/llm_service.py`** (lines 120-145)
   - Changed `model_kwargs` to `extra_body` for OpenRouter provider routing
   - Added comprehensive comments explaining the approach

## üîë Key Learnings

1. **`model_kwargs`** passes values as Python keyword arguments to the SDK
2. **`extra_body`** passes values directly in the JSON request body
3. OpenRouter-specific fields (like `provider`) must use `extra_body`
4. Tool support requires proper provider routing configuration
5. MCP tool loading was never the problem - it was the LLM configuration

## ‚úÖ Summary

**Issue**: Agents with MCP tools couldn't use tools with OpenRouter (404 error)  
**Root Cause**: Missing provider routing configuration after previous TypeError fix  
**Solution**: Use `extra_body` instead of `model_kwargs` to pass OpenRouter routing  
**Status**: ‚úÖ **FIXED**  
**Impact**: OpenRouter agents can now successfully use MCP tools  
**Compatibility**: All LLM providers (OpenRouter, Groq, OpenAI, Anthropic) now work correctly
